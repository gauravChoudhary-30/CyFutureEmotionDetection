{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXPH30jdAe5q",
        "outputId": "46d631b7-4119-4857-8233-7a298604db9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy scikit-learn tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "NacSzSF1AreL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"training.csv\")\n",
        "val_df = pd.read_csv(\"validation.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Validation shape:\", val_df.shape)\n",
        "print(\"Test shape:\", test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZZ35iOSBPNP",
        "outputId": "4681e175-3aea-4c36-c836-60bafe5a968d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (16000, 2)\n",
            "Validation shape: (2000, 2)\n",
            "Test shape: (2000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and pad sequences\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_df['text'])\n",
        "\n",
        "# Convert text to sequences\n",
        "max_len = 100  # adjust as needed\n",
        "X_train = pad_sequences(tokenizer.texts_to_sequences(train_df['text']), maxlen=max_len)\n",
        "X_val = pad_sequences(tokenizer.texts_to_sequences(val_df['text']), maxlen=max_len)\n",
        "X_test = pad_sequences(tokenizer.texts_to_sequences(test_df['text']), maxlen=max_len)\n",
        "\n",
        "# Labels\n",
        "y_train = train_df['label'].values\n",
        "y_val = val_df['label'].values\n",
        "y_test = test_df['label'].values\n",
        "\n",
        "num_classes = len(set(y_train))\n"
      ],
      "metadata": {
        "id": "F1uICUhvBc39"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_len),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "FoKFr-zqBfkG",
        "outputId": "3ceb7497-1a5a-484e-d936-55a29a68bff0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUr5mA1XBit7",
        "outputId": "f11e9c31-6e5b-4c10-9ec8-0f018cc64030"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 66ms/step - accuracy: 0.3727 - loss: 1.5397 - val_accuracy: 0.6875 - val_loss: 0.8134\n",
            "Epoch 2/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 64ms/step - accuracy: 0.7298 - loss: 0.6708 - val_accuracy: 0.7735 - val_loss: 0.5671\n",
            "Epoch 3/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 63ms/step - accuracy: 0.8675 - loss: 0.3325 - val_accuracy: 0.9070 - val_loss: 0.3161\n",
            "Epoch 4/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 63ms/step - accuracy: 0.9592 - loss: 0.1373 - val_accuracy: 0.9130 - val_loss: 0.3348\n",
            "Epoch 5/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 69ms/step - accuracy: 0.9712 - loss: 0.0928 - val_accuracy: 0.9225 - val_loss: 0.2787\n",
            "Epoch 6/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 67ms/step - accuracy: 0.9769 - loss: 0.0752 - val_accuracy: 0.9135 - val_loss: 0.2955\n",
            "Epoch 7/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 68ms/step - accuracy: 0.9781 - loss: 0.0702 - val_accuracy: 0.9180 - val_loss: 0.3351\n",
            "Epoch 8/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 70ms/step - accuracy: 0.9887 - loss: 0.0394 - val_accuracy: 0.9150 - val_loss: 0.3516\n",
            "Epoch 9/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 64ms/step - accuracy: 0.9858 - loss: 0.0424 - val_accuracy: 0.9110 - val_loss: 0.3996\n",
            "Epoch 10/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 65ms/step - accuracy: 0.9879 - loss: 0.0382 - val_accuracy: 0.9115 - val_loss: 0.4189\n",
            "Epoch 11/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 69ms/step - accuracy: 0.9902 - loss: 0.0304 - val_accuracy: 0.9100 - val_loss: 0.4264\n",
            "Epoch 12/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 68ms/step - accuracy: 0.9901 - loss: 0.0321 - val_accuracy: 0.9085 - val_loss: 0.3912\n",
            "Epoch 13/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 67ms/step - accuracy: 0.9924 - loss: 0.0259 - val_accuracy: 0.9120 - val_loss: 0.4352\n",
            "Epoch 14/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 67ms/step - accuracy: 0.9916 - loss: 0.0250 - val_accuracy: 0.9065 - val_loss: 0.4416\n",
            "Epoch 15/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 65ms/step - accuracy: 0.9910 - loss: 0.0269 - val_accuracy: 0.9160 - val_loss: 0.4225\n",
            "Epoch 16/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 65ms/step - accuracy: 0.9922 - loss: 0.0233 - val_accuracy: 0.9155 - val_loss: 0.4100\n",
            "Epoch 17/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 65ms/step - accuracy: 0.9939 - loss: 0.0173 - val_accuracy: 0.9100 - val_loss: 0.4200\n",
            "Epoch 18/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 67ms/step - accuracy: 0.9936 - loss: 0.0192 - val_accuracy: 0.9140 - val_loss: 0.4267\n",
            "Epoch 19/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.9917 - loss: 0.0216 - val_accuracy: 0.9050 - val_loss: 0.4700\n",
            "Epoch 20/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.9935 - loss: 0.0192 - val_accuracy: 0.9125 - val_loss: 0.4425\n",
            "Epoch 21/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 66ms/step - accuracy: 0.9949 - loss: 0.0162 - val_accuracy: 0.9125 - val_loss: 0.4572\n",
            "Epoch 22/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 64ms/step - accuracy: 0.9938 - loss: 0.0151 - val_accuracy: 0.9200 - val_loss: 0.5037\n",
            "Epoch 23/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 73ms/step - accuracy: 0.9931 - loss: 0.0176 - val_accuracy: 0.9125 - val_loss: 0.5090\n",
            "Epoch 24/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 67ms/step - accuracy: 0.9944 - loss: 0.0147 - val_accuracy: 0.9065 - val_loss: 0.5533\n",
            "Epoch 25/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 67ms/step - accuracy: 0.9944 - loss: 0.0175 - val_accuracy: 0.9140 - val_loss: 0.5510\n",
            "Epoch 26/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 66ms/step - accuracy: 0.9943 - loss: 0.0165 - val_accuracy: 0.9115 - val_loss: 0.4716\n",
            "Epoch 27/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 65ms/step - accuracy: 0.9959 - loss: 0.0126 - val_accuracy: 0.9145 - val_loss: 0.4738\n",
            "Epoch 28/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 66ms/step - accuracy: 0.9955 - loss: 0.0109 - val_accuracy: 0.9150 - val_loss: 0.5195\n",
            "Epoch 29/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 65ms/step - accuracy: 0.9959 - loss: 0.0099 - val_accuracy: 0.9030 - val_loss: 0.5586\n",
            "Epoch 30/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 66ms/step - accuracy: 0.9965 - loss: 0.0127 - val_accuracy: 0.9155 - val_loss: 0.5274\n",
            "Epoch 31/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 67ms/step - accuracy: 0.9943 - loss: 0.0166 - val_accuracy: 0.9150 - val_loss: 0.5361\n",
            "Epoch 32/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 66ms/step - accuracy: 0.9958 - loss: 0.0099 - val_accuracy: 0.9115 - val_loss: 0.5670\n",
            "Epoch 33/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 65ms/step - accuracy: 0.9964 - loss: 0.0080 - val_accuracy: 0.9170 - val_loss: 0.5622\n",
            "Epoch 34/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 69ms/step - accuracy: 0.9966 - loss: 0.0079 - val_accuracy: 0.9160 - val_loss: 0.5799\n",
            "Epoch 35/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 67ms/step - accuracy: 0.9970 - loss: 0.0090 - val_accuracy: 0.9110 - val_loss: 0.6700\n",
            "Epoch 36/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 67ms/step - accuracy: 0.9965 - loss: 0.0088 - val_accuracy: 0.9090 - val_loss: 0.6102\n",
            "Epoch 37/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 65ms/step - accuracy: 0.9950 - loss: 0.0131 - val_accuracy: 0.9120 - val_loss: 0.6542\n",
            "Epoch 38/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 68ms/step - accuracy: 0.9949 - loss: 0.0140 - val_accuracy: 0.9140 - val_loss: 0.5713\n",
            "Epoch 39/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 67ms/step - accuracy: 0.9966 - loss: 0.0082 - val_accuracy: 0.9055 - val_loss: 0.5889\n",
            "Epoch 40/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 67ms/step - accuracy: 0.9969 - loss: 0.0077 - val_accuracy: 0.9060 - val_loss: 0.6283\n",
            "Epoch 41/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 67ms/step - accuracy: 0.9973 - loss: 0.0061 - val_accuracy: 0.9035 - val_loss: 0.6158\n",
            "Epoch 42/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.9964 - loss: 0.0087 - val_accuracy: 0.9105 - val_loss: 0.7104\n",
            "Epoch 43/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 66ms/step - accuracy: 0.9968 - loss: 0.0067 - val_accuracy: 0.9075 - val_loss: 0.7373\n",
            "Epoch 44/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 65ms/step - accuracy: 0.9957 - loss: 0.0073 - val_accuracy: 0.9100 - val_loss: 0.7105\n",
            "Epoch 45/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 68ms/step - accuracy: 0.9978 - loss: 0.0046 - val_accuracy: 0.9095 - val_loss: 0.6800\n",
            "Epoch 46/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.9959 - loss: 0.0073 - val_accuracy: 0.9100 - val_loss: 0.7504\n",
            "Epoch 47/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.9957 - loss: 0.0161 - val_accuracy: 0.9080 - val_loss: 0.5940\n",
            "Epoch 48/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 65ms/step - accuracy: 0.9954 - loss: 0.0134 - val_accuracy: 0.9165 - val_loss: 0.6086\n",
            "Epoch 49/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 67ms/step - accuracy: 0.9966 - loss: 0.0081 - val_accuracy: 0.9130 - val_loss: 0.6551\n",
            "Epoch 50/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 67ms/step - accuracy: 0.9963 - loss: 0.0077 - val_accuracy: 0.9110 - val_loss: 0.6554\n",
            "Epoch 51/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 69ms/step - accuracy: 0.9971 - loss: 0.0073 - val_accuracy: 0.9105 - val_loss: 0.6068\n",
            "Epoch 52/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 69ms/step - accuracy: 0.9974 - loss: 0.0071 - val_accuracy: 0.9100 - val_loss: 0.6668\n",
            "Epoch 53/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.9963 - loss: 0.0079 - val_accuracy: 0.9105 - val_loss: 0.6328\n",
            "Epoch 54/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 67ms/step - accuracy: 0.9962 - loss: 0.0080 - val_accuracy: 0.9195 - val_loss: 0.6368\n",
            "Epoch 55/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.9971 - loss: 0.0062 - val_accuracy: 0.9145 - val_loss: 0.6555\n",
            "Epoch 56/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.9974 - loss: 0.0050 - val_accuracy: 0.9120 - val_loss: 0.6806\n",
            "Epoch 57/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 69ms/step - accuracy: 0.9968 - loss: 0.0061 - val_accuracy: 0.9160 - val_loss: 0.7170\n",
            "Epoch 58/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.9963 - loss: 0.0056 - val_accuracy: 0.9090 - val_loss: 0.7331\n",
            "Epoch 59/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 67ms/step - accuracy: 0.9959 - loss: 0.0074 - val_accuracy: 0.9105 - val_loss: 0.6323\n",
            "Epoch 60/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 66ms/step - accuracy: 0.9977 - loss: 0.0076 - val_accuracy: 0.9040 - val_loss: 0.7863\n",
            "Epoch 61/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 66ms/step - accuracy: 0.9961 - loss: 0.0067 - val_accuracy: 0.9090 - val_loss: 0.7780\n",
            "Epoch 62/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 69ms/step - accuracy: 0.9971 - loss: 0.0059 - val_accuracy: 0.9135 - val_loss: 0.7680\n",
            "Epoch 63/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 68ms/step - accuracy: 0.9978 - loss: 0.0068 - val_accuracy: 0.9155 - val_loss: 0.6569\n",
            "Epoch 64/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 66ms/step - accuracy: 0.9969 - loss: 0.0064 - val_accuracy: 0.9125 - val_loss: 0.7445\n",
            "Epoch 65/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 69ms/step - accuracy: 0.9976 - loss: 0.0050 - val_accuracy: 0.9145 - val_loss: 0.7311\n",
            "Epoch 66/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 69ms/step - accuracy: 0.9976 - loss: 0.0047 - val_accuracy: 0.9100 - val_loss: 0.7672\n",
            "Epoch 67/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 65ms/step - accuracy: 0.9961 - loss: 0.0089 - val_accuracy: 0.9115 - val_loss: 0.7056\n",
            "Epoch 68/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 69ms/step - accuracy: 0.9975 - loss: 0.0059 - val_accuracy: 0.9100 - val_loss: 0.7089\n",
            "Epoch 69/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 69ms/step - accuracy: 0.9968 - loss: 0.0094 - val_accuracy: 0.9180 - val_loss: 0.6897\n",
            "Epoch 70/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 70ms/step - accuracy: 0.9970 - loss: 0.0074 - val_accuracy: 0.9210 - val_loss: 0.6724\n",
            "Epoch 71/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 70ms/step - accuracy: 0.9979 - loss: 0.0040 - val_accuracy: 0.9215 - val_loss: 0.7094\n",
            "Epoch 72/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 70ms/step - accuracy: 0.9969 - loss: 0.0066 - val_accuracy: 0.9155 - val_loss: 0.7212\n",
            "Epoch 73/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 69ms/step - accuracy: 0.9976 - loss: 0.0053 - val_accuracy: 0.9115 - val_loss: 0.7519\n",
            "Epoch 74/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 68ms/step - accuracy: 0.9970 - loss: 0.0131 - val_accuracy: 0.9140 - val_loss: 0.6979\n",
            "Epoch 75/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.9974 - loss: 0.0055 - val_accuracy: 0.9165 - val_loss: 0.7100\n",
            "Epoch 76/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.9976 - loss: 0.0065 - val_accuracy: 0.9170 - val_loss: 0.6529\n",
            "Epoch 77/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 69ms/step - accuracy: 0.9973 - loss: 0.0068 - val_accuracy: 0.9190 - val_loss: 0.6083\n",
            "Epoch 78/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 66ms/step - accuracy: 0.9977 - loss: 0.0050 - val_accuracy: 0.9145 - val_loss: 0.7052\n",
            "Epoch 79/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 69ms/step - accuracy: 0.9975 - loss: 0.0047 - val_accuracy: 0.9155 - val_loss: 0.7440\n",
            "Epoch 80/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 69ms/step - accuracy: 0.9972 - loss: 0.0050 - val_accuracy: 0.9165 - val_loss: 0.7374\n",
            "Epoch 81/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 69ms/step - accuracy: 0.9983 - loss: 0.0037 - val_accuracy: 0.9135 - val_loss: 0.7637\n",
            "Epoch 82/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 66ms/step - accuracy: 0.9978 - loss: 0.0042 - val_accuracy: 0.9110 - val_loss: 0.9104\n",
            "Epoch 83/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 66ms/step - accuracy: 0.9964 - loss: 0.0065 - val_accuracy: 0.9115 - val_loss: 0.8432\n",
            "Epoch 84/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 73ms/step - accuracy: 0.9974 - loss: 0.0052 - val_accuracy: 0.9105 - val_loss: 0.8176\n",
            "Epoch 85/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 70ms/step - accuracy: 0.9971 - loss: 0.0044 - val_accuracy: 0.9075 - val_loss: 0.8932\n",
            "Epoch 86/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 67ms/step - accuracy: 0.9977 - loss: 0.0042 - val_accuracy: 0.9085 - val_loss: 0.8860\n",
            "Epoch 87/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 66ms/step - accuracy: 0.9976 - loss: 0.0043 - val_accuracy: 0.9050 - val_loss: 0.9073\n",
            "Epoch 88/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 71ms/step - accuracy: 0.9968 - loss: 0.0103 - val_accuracy: 0.9140 - val_loss: 0.6473\n",
            "Epoch 89/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 70ms/step - accuracy: 0.9979 - loss: 0.0046 - val_accuracy: 0.9040 - val_loss: 0.6990\n",
            "Epoch 90/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 68ms/step - accuracy: 0.9972 - loss: 0.0077 - val_accuracy: 0.9130 - val_loss: 0.6681\n",
            "Epoch 91/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 68ms/step - accuracy: 0.9975 - loss: 0.0044 - val_accuracy: 0.9175 - val_loss: 0.6956\n",
            "Epoch 92/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 70ms/step - accuracy: 0.9976 - loss: 0.0045 - val_accuracy: 0.9185 - val_loss: 0.7260\n",
            "Epoch 93/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 69ms/step - accuracy: 0.9979 - loss: 0.0044 - val_accuracy: 0.9195 - val_loss: 0.7059\n",
            "Epoch 94/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 66ms/step - accuracy: 0.9977 - loss: 0.0043 - val_accuracy: 0.9175 - val_loss: 0.8455\n",
            "Epoch 95/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 69ms/step - accuracy: 0.9971 - loss: 0.0116 - val_accuracy: 0.9145 - val_loss: 0.7833\n",
            "Epoch 96/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 70ms/step - accuracy: 0.9978 - loss: 0.0039 - val_accuracy: 0.9100 - val_loss: 0.8574\n",
            "Epoch 97/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 71ms/step - accuracy: 0.9977 - loss: 0.0050 - val_accuracy: 0.9055 - val_loss: 0.8540\n",
            "Epoch 98/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 70ms/step - accuracy: 0.9963 - loss: 0.0078 - val_accuracy: 0.9130 - val_loss: 0.7555\n",
            "Epoch 99/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 70ms/step - accuracy: 0.9974 - loss: 0.0043 - val_accuracy: 0.9125 - val_loss: 0.7706\n",
            "Epoch 100/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 70ms/step - accuracy: 0.9976 - loss: 0.0045 - val_accuracy: 0.9135 - val_loss: 0.7672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Classification Report\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxigBjv9TwYe",
        "outputId": "6fbeea29-368a-460a-943c-da9226684b9c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9038 - loss: 0.9405\n",
            "\n",
            "Test Accuracy: 0.9050\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.95       581\n",
            "           1       0.93      0.93      0.93       695\n",
            "           2       0.79      0.81      0.80       159\n",
            "           3       0.88      0.91      0.89       275\n",
            "           4       0.88      0.82      0.85       224\n",
            "           5       0.70      0.73      0.71        66\n",
            "\n",
            "    accuracy                           0.91      2000\n",
            "   macro avg       0.85      0.86      0.86      2000\n",
            "weighted avg       0.91      0.91      0.91      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"emotion_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQqavSQMUuJR",
        "outputId": "b26d66d4-1f2f-41c3-e995-9775df0775a7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities\n",
        "val_probs = model.predict(X_val)\n",
        "test_probs = model.predict(X_test)\n",
        "\n",
        "# Get the predicted class (argmax to convert from probabilities to class index)\n",
        "val_preds = np.argmax(val_probs, axis=1)\n",
        "test_preds = np.argmax(test_probs, axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFeqmOGiU1r7",
        "outputId": "505f8ab7-0104-4f95-b514-e3115d246f22"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Validation Set Evaluation\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\n",
        "print(\"Validation Classification Report:\\n\", classification_report(y_val, val_preds))\n",
        "print(\"Validation Confusion Matrix:\\n\", confusion_matrix(y_val, val_preds))\n",
        "\n",
        "# Test Set Evaluation\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, test_preds))\n",
        "print(\"Test Classification Report:\\n\", classification_report(y_test, test_preds))\n",
        "print(\"Test Confusion Matrix:\\n\", confusion_matrix(y_test, test_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byjtevGJU5KB",
        "outputId": "7cd894b0-f2df-4e12-8ea0-eb9de304a8e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9135\n",
            "Validation Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95       550\n",
            "           1       0.94      0.93      0.93       704\n",
            "           2       0.81      0.84      0.83       178\n",
            "           3       0.91      0.94      0.92       275\n",
            "           4       0.91      0.79      0.85       212\n",
            "           5       0.84      0.83      0.83        81\n",
            "\n",
            "    accuracy                           0.91      2000\n",
            "   macro avg       0.89      0.88      0.89      2000\n",
            "weighted avg       0.91      0.91      0.91      2000\n",
            "\n",
            "Validation Confusion Matrix:\n",
            " [[531   6   3   6   4   0]\n",
            " [ 12 652  28   7   3   2]\n",
            " [  3  21 150   2   1   1]\n",
            " [  7   3   3 259   3   0]\n",
            " [ 15   7   1  11 168  10]\n",
            " [  3   5   0   1   5  67]]\n",
            "Test Accuracy: 0.905\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.95       581\n",
            "           1       0.93      0.93      0.93       695\n",
            "           2       0.79      0.81      0.80       159\n",
            "           3       0.88      0.91      0.89       275\n",
            "           4       0.88      0.82      0.85       224\n",
            "           5       0.70      0.73      0.71        66\n",
            "\n",
            "    accuracy                           0.91      2000\n",
            "   macro avg       0.85      0.86      0.86      2000\n",
            "weighted avg       0.91      0.91      0.91      2000\n",
            "\n",
            "Test Confusion Matrix:\n",
            " [[555   6   0  14   5   1]\n",
            " [  5 646  30   5   2   7]\n",
            " [  2  23 128   5   1   0]\n",
            " [  8   8   2 250   7   0]\n",
            " [ 12   4   3   9 183  13]\n",
            " [  3   5   0   1   9  48]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(train_df['label'])\n",
        "\n",
        "# Encode labels\n",
        "y_train = label_encoder.transform(train_df['label'])\n",
        "y_val = label_encoder.transform(val_df['label'])\n",
        "y_test = label_encoder.transform(test_df['label'])\n",
        "\n",
        "# When converting predictions back to readable labels:\n",
        "results_df['label'] = label_encoder.inverse_transform(y_test)\n",
        "results_df['predicted'] = label_encoder.inverse_transform(test_preds)\n"
      ],
      "metadata": {
        "id": "Vy3YWnlnU9Rg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with NaN labels\n",
        "test_df_clean = test_df.dropna(subset=['label'])\n",
        "X_test_clean = pad_sequences(tokenizer.texts_to_sequences(test_df_clean['text']), maxlen=max_len)\n",
        "y_test_clean = label_encoder.transform(test_df_clean['label'])\n",
        "\n",
        "# Predict on clean set\n",
        "test_preds_clean = np.argmax(model.predict(X_test_clean), axis=1)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Clean Test Accuracy:\", accuracy_score(y_test_clean, test_preds_clean))\n",
        "print(\"Clean Test Classification Report:\\n\", classification_report(y_test_clean, test_preds_clean))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lxn5dbQgWQ7-",
        "outputId": "8bc24cbd-c319-488d-95f8-503384e26519"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
            "Clean Test Accuracy: 0.905\n",
            "Clean Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.95       581\n",
            "           1       0.93      0.93      0.93       695\n",
            "           2       0.79      0.81      0.80       159\n",
            "           3       0.88      0.91      0.89       275\n",
            "           4       0.88      0.82      0.85       224\n",
            "           5       0.70      0.73      0.71        66\n",
            "\n",
            "    accuracy                           0.91      2000\n",
            "   macro avg       0.85      0.86      0.86      2000\n",
            "weighted avg       0.91      0.91      0.91      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get DataFrame with actual and predicted labels\n",
        "test_df_clean['predicted'] = label_encoder.inverse_transform(test_preds_clean)\n",
        "test_df_clean['actual'] = test_df_clean['label']\n",
        "\n",
        "# Show misclassified\n",
        "misclassified = test_df_clean[test_df_clean['predicted'] != test_df_clean['actual']]\n",
        "# print(misclassified[['text', 'actual', 'predicted']].head(10))\n",
        "print(test_df_clean[['text', 'actual', 'predicted']].head(100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22ElU2K-WUQX",
        "outputId": "06b6d152-990b-4ff2-b8f6-701e7c6f031f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 text  actual  predicted\n",
            "0   im feeling rather rotten so im not very ambiti...       0          0\n",
            "1           im updating my blog because i feel shitty       0          0\n",
            "2   i never make her separate from me because i do...       0          0\n",
            "3   i left with my bouquet of red and yellow tulip...       1          1\n",
            "4     i was feeling a little vain when i did this one       0          0\n",
            "..                                                ...     ...        ...\n",
            "95  im feeling angry at someone i do something tho...       3          3\n",
            "96  i love neglecting this blog but sometimes i fe...       2          2\n",
            "97  i lay in bed feeling as though i were awaiting...       0          0\n",
            "98    i feel my heart is tortured by what i have done       3          3\n",
            "99  i was still feeling weepy and strung out so ma...       0          0\n",
            "\n",
            "[100 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load saved model\n",
        "model = load_model(\"emotion_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMBppN-bZnqE",
        "outputId": "da8c24da-3566-4a63-f148-db3c216cfd11"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion(texts, tokenizer, model, max_len=100):\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "\n",
        "    # Preprocess input\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "    padded = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "    # Predict\n",
        "    preds = model.predict(padded)\n",
        "    pred_labels = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Map labels\n",
        "    label_map = {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'}\n",
        "    return [label_map.get(label, \"unknown\") for label in pred_labels]"
      ],
      "metadata": {
        "id": "cu8M2gUIZvN3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example texts\n",
        "my_texts = [\n",
        "    \"I can't stop crying, I miss them so much.\",\n",
        "    \"I just got a promotion! So excited!\",\n",
        "    \"I hate being ignored.\",\n",
        "    \"That was unexpected but wonderful!\",\n",
        "    \"Why do I feel so anxious lately?\"\n",
        "]\n",
        "\n",
        "# Predict emotions\n",
        "predicted_emotions = predict_emotion(my_texts, tokenizer, model)\n",
        "for txt, emotion in zip(my_texts, predicted_emotions):\n",
        "    print(f\"Text: {txt}\\nPredicted Emotion: {emotion}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKxoctOHZyUs",
        "outputId": "586036ad-cad1-44eb-8e07-fed8a843c425"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step\n",
            "Text: I can't stop crying, I miss them so much.\n",
            "Predicted Emotion: surprise\n",
            "\n",
            "Text: I just got a promotion! So excited!\n",
            "Predicted Emotion: joy\n",
            "\n",
            "Text: I hate being ignored.\n",
            "Predicted Emotion: sadness\n",
            "\n",
            "Text: That was unexpected but wonderful!\n",
            "Predicted Emotion: joy\n",
            "\n",
            "Text: Why do I feel so anxious lately?\n",
            "Predicted Emotion: fear\n",
            "\n"
          ]
        }
      ]
    }
  ]
}